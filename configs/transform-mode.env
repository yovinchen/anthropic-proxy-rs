# ============================================================
# Transform 模式配置 (Anthropic API → OpenAI 兼容后端)
# ============================================================
# 
# 用途: 将 Anthropic API 请求转换为 OpenAI 格式，发送到 OpenRouter 等后端
# 适用场景: 使用 Claude Code 但通过 OpenRouter 访问模型
#
# 请求流程:
#   客户端 (Anthropic SDK) 
#     → anthropic-proxy (转换) 
#       → OpenRouter/OpenAI 兼容后端
#
# ============================================================

# 路由模式: transform (默认)
ROUTING_MODE=transform

# ============================================================
# 上游服务配置 (必需)
# ============================================================

# OpenRouter 配置
UPSTREAM_BASE_URL=https://openrouter.ai/api
UPSTREAM_API_KEY=sk-or-v1-your-openrouter-api-key

# 或者使用 OpenAI 官方
# UPSTREAM_BASE_URL=https://api.openai.com
# UPSTREAM_API_KEY=sk-your-openai-api-key

# 或者使用本地 Ollama
# UPSTREAM_BASE_URL=http://localhost:11434
# UPSTREAM_API_KEY=

# ============================================================
# 模型覆盖配置 (可选)
# ============================================================

# 扩展思考模式使用的模型 (当请求包含 thinking 参数时)
REASONING_MODEL=anthropic/claude-3.5-sonnet

# 普通补全使用的模型
COMPLETION_MODEL=anthropic/claude-3-haiku

# ============================================================
# 服务配置
# ============================================================

PORT=3000
DEBUG=false
VERBOSE=false

# ============================================================
# 测试命令
# ============================================================
#
# 1. 启动代理:
#    anthropic-proxy --config configs/transform-mode.env
#
# 2. 测试请求:
#    curl http://localhost:3000/v1/messages \
#      -H "Content-Type: application/json" \
#      -d '{
#        "model": "claude-3-5-sonnet-20241022",
#        "max_tokens": 100,
#        "messages": [{"role": "user", "content": "Hello!"}]
#      }'
#
# 3. 使用 Claude Code:
#    ANTHROPIC_BASE_URL=http://localhost:3000 claude
#
# ============================================================
